{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0 - BERT .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FruQ8eRaU5fM",
        "colab_type": "text"
      },
      "source": [
        "# Download dataset from kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IG5DHVlsUpdX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/drive/My Drive/kaggle\"\n",
        "%cd /content/drive/My Drive/colab_data/datasets\n",
        "if not os.path.isdir('sentiment-analysis-on-movie-reviews'):\n",
        "  os.mkdir('sentiment-analysis-on-movie-reviews')\n",
        "%cd sentiment-analysis-on-movie-reviews\n",
        "!kaggle competitions download -c sentiment-analysis-on-movie-reviews\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fz9b4t8QVoed",
        "colab_type": "text"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlM1uIdPWIzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -qq transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJqg8LP5Vk7h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoMcC08DVnTu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "ROOT_DIR = '/content/drive/My Drive/colab_data/datasets/sentiment-analysis-on-movie-reviews'\n",
        "LABELS = ['negative','somewhat negative', 'neutral', 'somewhat positive', 'positive']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Fv3GzWuV9Bv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(os.path.join(ROOT_DIR, 'train.tsv.zip'), sep=\"\\t\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de-ZFkPBXws4",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKVLkZa7YYRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "import pprint\n",
        "\n",
        "PRE_TRAINED_MODEL_NAME = 'bert-base-uncased'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81v0rbH5iPXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# adjust plot colors if notebook background is dark\n",
        "default_color = 'white'\n",
        "mpl.rcParams['axes.labelcolor'] = default_color\n",
        "mpl.rcParams['xtick.color'] = default_color\n",
        "mpl.rcParams['ytick.color'] = default_color\n",
        "mpl.rcParams['axes.titlecolor'] = default_color"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1BaE3b9ZK3t",
        "colab_type": "text"
      },
      "source": [
        "Ref for pretrained models: https://huggingface.co/transformers/pretrained_models.html?highlight=pretrained%20names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYVr2bskXsZc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_reviews = list(df['Phrase'][:5].values)\n",
        "for text in sample_reviews:\n",
        "  print(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGaghQZdXv93",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLBuTxEpcB3H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.max_model_input_sizes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6r6SrGVJZyu3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_inputs = tokenizer(sample_reviews)\n",
        "pprint.pprint(encoded_inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCJLU1R_dD8k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for ids in encoded_inputs['input_ids']:\n",
        "  print(tokenizer.decode(ids))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3v_ujUv2dUhd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_inputs = tokenizer(\n",
        "                      sample_reviews,\n",
        "                      max_length=64,\n",
        "                      add_special_tokens=True,\n",
        "                      return_token_type_ids=False,\n",
        "                      pad_to_max_length=True,\n",
        "                      truncation=True,\n",
        "                      return_attention_mask=True,\n",
        "                      return_tensors='pt'\n",
        "                    )\n",
        "for ids in encoded_inputs['input_ids']:\n",
        "  print(tokenizer.decode(ids))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfGtW0CHfaPr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_lens = []\n",
        "for txt in df['Phrase']:\n",
        "  tokens = tokenizer.encode(txt, max_length=512, truncation=True)\n",
        "  token_lens.append(len(tokens))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "np20yi-4iy9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(max(token_lens))\n",
        "sns.distplot(token_lens)\n",
        "plt.xlim([0, 100]);\n",
        "plt.xlabel('Token count');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOKGYJQbjYCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = 64\n",
        "BATCH_SIZE = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E1-qIplkV9r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ReviewDataset(Dataset):\n",
        "  def __init__(self, df, tokenizer, max_len):\n",
        "    self.input = df['Phrase'].to_numpy();\n",
        "    self.output = df['Sentiment'].to_numpy();\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    review = str(self.input[idx])\n",
        "    label = self.output[idx]\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      pad_to_max_length=True,\n",
        "      truncation=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt')\n",
        "\n",
        "    return {\n",
        "      'input_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'label': torch.tensor(label, dtype=torch.long)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYICA5pfmHiX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df, val_df = train_test_split(df, test_size=0.2)\n",
        "print(train_df.shape)\n",
        "print(val_df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHoLPcTil-Ur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = ReviewDataset(\n",
        "    train_df,\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=MAX_LEN)\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-WDAyHSnKjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_dataset = ReviewDataset(\n",
        "    val_df,\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=MAX_LEN)\n",
        "\n",
        "val_dataloader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaYX7aXmvyEF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_train_batchs = len(train_dataloader)\n",
        "nb_val_batchs = len(val_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNt-LhtMohR6",
        "colab_type": "text"
      },
      "source": [
        "# BERT Model: Fine-Tuning SequenceClassification\n",
        "\n",
        "ref: https://huggingface.co/transformers/training.html#pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sl9e2EvipV1K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "EPOCHS = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBsVV70atRYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "print (use_cuda)\n",
        "\n",
        "if use_cuda:\n",
        "  current_device = torch.cuda.current_device()\n",
        "  print(torch.cuda.get_device_name(current_device))\n",
        "else:\n",
        "  current_device = torch.device(\"cpu\")\n",
        "\n",
        "def print_(loss, mode=\"Training\"):\n",
        "  print (mode + \":The loss calculated: \", loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOaH6vddrUhW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=5)\n",
        "model.to(current_device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X-CtNfcrIJz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRkkrcv_sAKI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(EPOCHS):\n",
        "  print(\"Epoch:\",i+1)\n",
        "  model = model.train()\n",
        "  running_loss = 0.0;\n",
        "  for i_batch, sample_batch in enumerate(train_dataloader):\n",
        "      input_ids = sample_batch['input_ids']\n",
        "      attention_masks = sample_batch['attention_mask']\n",
        "      labels = sample_batch['label']\n",
        "\n",
        "      input_ids = input_ids.to(current_device)\n",
        "      attention_masks = attention_masks.to(current_device)\n",
        "      labels = labels.to(current_device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      _y = model(input_ids, attention_mask=attention_masks)\n",
        "      loss = loss_fn(_y[0], labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "      running_loss += loss.item()\n",
        "  print_(running_loss/nb_train_batchs)\n",
        "\n",
        "\n",
        "  model = model.eval()\n",
        "  running_loss = 0.0;\n",
        "  for i_batch, sample_batch in enumerate(val_dataloader):\n",
        "      input_ids = sample_batch['input_ids']\n",
        "      attention_masks = sample_batch['attention_mask']\n",
        "      labels = sample_batch['label']\n",
        "\n",
        "      input_ids = input_ids.to(current_device)\n",
        "      attention_masks = attention_masks.to(current_device)\n",
        "      labels = labels.to(current_device)\n",
        "\n",
        "      _y = model(input_ids, attention_mask=attention_masks)\n",
        "      loss = loss_fn(_y[0], labels)\n",
        "\n",
        "      running_loss += loss.item()\n",
        "  print_(running_loss/nb_train_batchs, \"Evaluation\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agyRolhR0_95",
        "colab_type": "text"
      },
      "source": [
        "# BERT Model: Fine-Tuning Custom Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-coG2RbjnaB_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "    def __init__(self, n_classes, bert_model):\n",
        "      super(SentimentClassifier, self).__init__()\n",
        "      self.bert = bert_model\n",
        "      self.drop = nn.Dropout(p=0.1)\n",
        "      self.mlc_1 = nn.Linear(self.bert.config.hidden_size, 100)\n",
        "      self.mlc_2 = nn.Linear(100, n_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "      _, pooled_output = self.bert(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask)\n",
        "      _y = self.drop(pooled_output)\n",
        "      _y = self.mlc_1(_y)\n",
        "      _y = F.softmax(self.mlc_2(_y), dim=0)\n",
        "      return _y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMFF9JmA2O8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ber_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KXxxu1KoQ1p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = SentimentClassifier(5, ber_model)\n",
        "model.to(current_device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqcOsDb-3zkG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.train()\n",
        "running_loss = 0.0;\n",
        "for i_batch, sample_batch in enumerate(train_dataloader):\n",
        "  input_ids = sample_batch['input_ids']\n",
        "  attention_masks = sample_batch['attention_mask']\n",
        "  labels = sample_batch['label']\n",
        "\n",
        "  input_ids = input_ids.to(current_device)\n",
        "  attention_masks = attention_masks.to(current_device)\n",
        "  labels = labels.to(current_device)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  _y = model(input_ids, attention_mask=attention_masks)\n",
        "  loss = loss_fn(_y, labels)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  \n",
        "  running_loss += loss.item()\n",
        "print(running_loss/nb_train_batchs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAqIHOsh4zMN",
        "colab_type": "text"
      },
      "source": [
        "# Exercises:\n",
        "\n",
        "\n",
        "1.   Use Trainer Module from transformer package (ref: https://huggingface.co/transformers/training.html#trainer) \n",
        "\n"
      ]
    }
  ]
}